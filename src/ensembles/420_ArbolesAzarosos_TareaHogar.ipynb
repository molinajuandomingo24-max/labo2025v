{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molinajuandomingo24-max/labo2025v/blob/main/src/ensembles/420_ArbolesAzarosos_TareaHogar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "kgJ0E--L0n9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un arbol de decisión es un modelo débil, el aumento del poder predictivo proviene al ensamblar varios arboles de decisión.\n",
        "<br> Si promedio n arboles identicos, el resultados es exactamente el mismo que utilizar un solo arbol, necesito PERTURBAR cada arbol para disponer de variablidad"
      ],
      "metadata": {
        "id": "PgLdmWznXWGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "la variabilidad provendrá de estas fuentes:\n",
        "\n",
        "\n",
        "*   Perturbar el dataset\n",
        "*   Perturbar el algoritmo del arbol\n",
        "*   Perturbar el dataset y el algoritmo del arbol al mismo tiempo"
      ],
      "metadata": {
        "id": "FTnxMEOqYRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se verán estos tres algoritmos\n",
        "\n",
        "\n",
        "*   Arboles Azarosos\n",
        "*   Random Forest\n",
        "*   Gradient Boosting of Decision Trees"
      ],
      "metadata": {
        "id": "DHp1h9m-X7Rc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0ySYPfa7Zr"
      },
      "source": [
        "#### 4.01 Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9x9DnsNlZv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.02 Arboles Azarosos"
      ],
      "metadata": {
        "id": "qq0KVOtq1K5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arboles Azarosos es el nombre de un algoritmo trivial (por favor NO confundir con Random Forest)\n",
        "Qué tipo de perturbaciones se realizan en Arboles Azarosos\n",
        "* Se perturba el dataset\n",
        "* No se perturba el algoritmo, es siempre rpart original"
      ],
      "metadata": {
        "id": "HsNJjhlRo9jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada  arbolito de  Arboles Azarosos se entrena sobre un dataset perturbado,  que tiene exactamente la misma cantidad de registros pero solo un subconjunto de los atributos (campos)  del dataset, tomados al azar, de los originales.\n",
        "<br> En esta primera corrida, se construira cada arbol en un dataset utilizando el 50% de los campos"
      ],
      "metadata": {
        "id": "rq2HC28CpXBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "LrdtraBYJrsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDwdD0dCPRU"
      },
      "outputs": [],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "M8-Pyp6CCPRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 209353\n",
        "\n",
        "# parametros  arbol\n",
        "# entreno cada arbol con solo 50% de las variables variables\n",
        "#  por ahora, es fijo\n",
        "PARAM$feature_fraction <- 0.5\n",
        "\n",
        "PARAM$rpart$cp <- -1\n",
        "PARAM$rpart$minsplit <- 50\n",
        "PARAM$rpart$minbucket <- 20\n",
        "PARAM$rpart$maxdepth <- 6\n",
        "\n",
        "# voy a generar 512 arboles,\n",
        "#  a mas arboles mas tiempo de proceso y MEJOR MODELO,\n",
        "#  pero ganancias marginales\n",
        "PARAM$num_trees_max <- 512"
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"exp4020\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los dataset de entrenamiento y aplicacion\n",
        "dtrain <- dataset[foto_mes == 202107]\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# arreglo clase_ternaria por algun distraido \"\"\n",
        "dfuture[, clase_ternaria := NA ]"
      ],
      "metadata": {
        "id": "RA3cSJ6KaGwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establezco cuales son los campos que puedo usar para la prediccion\n",
        "# el copy() es por la Lazy Evaluation\n",
        "campos_buenos <- copy(setdiff(colnames(dtrain), c(\"clase_ternaria\")))"
      ],
      "metadata": {
        "id": "EByLkVMwaC8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# que tamanos de ensemble grabo a disco\n",
        "grabar <- c(1, 2, 4, 8, 16, 32, 64, 128, 256, 384, 512)"
      ],
      "metadata": {
        "id": "rHMrHwwpaB8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "# aqui se va acumulando la probabilidad del ensemble\n",
        "tb_prediccion[, prob_acumulada := 0]"
      ],
      "metadata": {
        "id": "bJHS2aeghw6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(PARAM$semilla_primigenia) # Establezco la semilla aleatoria"
      ],
      "metadata": {
        "id": "H_DGUB_fhzHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (arbolito in seq(PARAM$num_trees_max) ) {\n",
        "  message( arbolito, \" \")\n",
        "  qty_campos_a_utilizar <- as.integer(length(campos_buenos)\n",
        "    * PARAM$feature_fraction)\n",
        "\n",
        "  # elijo los campos al azar\n",
        "  campos_random <- sample(campos_buenos, qty_campos_a_utilizar)\n",
        "\n",
        "  # paso de un vector a un string con los elementos\n",
        "  # separados por un signo de \"+\"\n",
        "  # este hace falta para la formula\n",
        "  campos_random <- paste(campos_random, collapse= \" + \")\n",
        "\n",
        "  # armo la formula para rpart\n",
        "  formulita <- paste0(\"clase_ternaria ~ \", campos_random)\n",
        "\n",
        "  # genero el arbol de decision\n",
        "  modelo <- rpart(formulita,\n",
        "    data= dtrain,\n",
        "    xval= 0,\n",
        "    control= PARAM$rpart\n",
        "  )\n",
        "\n",
        "  # aplico el modelo a los datos que no tienen clase\n",
        "  prediccion <- predict(modelo, dfuture, type= \"prob\")\n",
        "\n",
        "  tb_prediccion[, prob_acumulada := prob_acumulada + prediccion[, \"BAJA+2\"]]\n",
        "\n",
        "  if (arbolito %in% grabar) {\n",
        "    umbral_corte <- (1 / 40) * arbolito\n",
        "    tb_prediccion[, Predicted := as.numeric(prob_acumulada > umbral_corte)]\n",
        "\n",
        "    archivo_kaggle <- paste0(\n",
        "        \"KA420_\",\n",
        "        sprintf(\"%.3d\", arbolito), # para que tenga ceros adelante\n",
        "        \".csv\"\n",
        "      )\n",
        "\n",
        "    # grabo el archivo\n",
        "    fwrite( tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "      file= archivo_kaggle,\n",
        "      sep= \",\"\n",
        "    )\n",
        "\n",
        "    # subida a Kaggle\n",
        "    comando <- \"kaggle competitions submit\"\n",
        "    competencia <- \"-c labo-i-2025-ba-analista-sr\"\n",
        "    arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "    mensaje <- paste0(\"-m 'cp=\", PARAM$rpart$cp, \"  minsplit=\", PARAM$rpart$minsplit, \"  minbucket=\", PARAM$rpart$minbucket, \" maxdepth=\", PARAM$rpart$maxdepth, \"'\" )\n",
        "    linea <- paste( comando, competencia, arch, mensaje)\n",
        "    salida <- system(linea, intern=TRUE)\n",
        "    cat(salida)\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "j-xp2HQDhFmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "lgmvRHcfJpls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Inicio del Código R ---\n",
        "\n",
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection\n",
        "\n",
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"tools\") # Para basename\n",
        "\n",
        "# --- Parametros Fijos y Optimizables ---\n",
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 209353 # Su semilla primigenia\n",
        "\n",
        "# Parametros para Arboles Azarosos\n",
        "PARAM$feature_fraction <- 0.5  # Fracción de campos a usar en cada arbol\n",
        "PARAM$num_trees_optimo <- 32   # Número de árboles fijo para la optimización\n",
        "\n",
        "# Rangos para la optimización de hiperparámetros\n",
        "# Los valores se eligen para crear arboles potencialmente 'overfitteros'\n",
        "# (menor minsplit, mayor maxdepth) para el ensemble.\n",
        "PARAM$minsplit_values <- c(50, 40, 30, 20)\n",
        "PARAM$maxdepth_values <- c(6, 8, 10)\n",
        "PARAM$cp_value <- -1 # cp se mantiene fijo\n",
        "\n",
        "# --- Seteo de Directorios ---\n",
        "# Carpeta de trabajo\n",
        "# setwd(\"/content/buckets/b1/exp\") # Esta línea se asume ejecutada en el script Python\n",
        "experimento_base <- \"exp420_opt_ensemble32\"\n",
        "# Dir.create solo si no existe, si existe se borran archivos viejos para un experimento limpio\n",
        "dir.create(paste0(\"/content/buckets/b1/exp/\", experimento_base), showWarnings=FALSE)\n",
        "setwd(paste0(\"/content/buckets/b1/exp/\", experimento_base))\n",
        "\n",
        "# --- Lectura de Datos ---\n",
        "# Se asume que el archivo ya fue descargado en el setup de Python\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")\n",
        "\n",
        "# Defino los dataset de entrenamiento y aplicacion (futuro)\n",
        "dtrain <- dataset[foto_mes == 202107]\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# Arreglo clase_ternaria por algun distraido \"\"\n",
        "dfuture[, clase_ternaria := NA ]\n",
        "\n",
        "# Establezco cuales son los campos que puedo usar para la prediccion\n",
        "campos_buenos <- copy(setdiff(colnames(dtrain), c(\"clase_ternaria\")))\n",
        "\n",
        "# --- Búsqueda de Hiperparámetros ---\n",
        "for (minsplit_actual in PARAM$minsplit_values) {\n",
        "  for (maxdepth_actual in PARAM$maxdepth_values) {\n",
        "\n",
        "    # 1. Definir los parámetros del arbolito para esta iteración\n",
        "    # Se ajusta minbucket para ser consistente con minsplit (minbucket = minsplit/2)\n",
        "    PARAM$rpart_current <- list(\n",
        "      cp = PARAM$cp_value,\n",
        "      minsplit = minsplit_actual,\n",
        "      minbucket = as.integer(minsplit_actual / 2),\n",
        "      maxdepth = maxdepth_actual\n",
        "    )\n",
        "\n",
        "    # Crear un subdirectorio para cada combinación de hiperparámetros\n",
        "    exp_detalle <- paste0(\"m\", minsplit_actual, \"_d\", maxdepth_actual)\n",
        "    dir.create(exp_detalle, showWarnings=FALSE)\n",
        "    setwd(exp_detalle)\n",
        "\n",
        "    cat(\"--- Optimizando: minsplit=\", minsplit_actual, \", maxdepth=\", maxdepth_actual, \" ---\\n\")\n",
        "\n",
        "    # Inicializar para el ensemble\n",
        "    tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "    tb_prediccion[, prob_acumulada := 0]\n",
        "\n",
        "    # Establezco la semilla aleatoria para reproducibilidad del ensemble\n",
        "    set.seed(PARAM$semilla_primigenia)\n",
        "\n",
        "    # Bucle para entrenar el ensemble de 32 arboles\n",
        "    for (arbolito in seq(PARAM$num_trees_optimo) ) {\n",
        "\n",
        "      qty_campos_a_utilizar <- as.integer(length(campos_buenos) * PARAM$feature_fraction)\n",
        "\n",
        "      # Elijo los campos al azar\n",
        "      # Usar una semilla específica del loop para reproducibilidad de la selección de campos\n",
        "      set.seed(PARAM$semilla_primigenia + arbolito)\n",
        "      campos_random <- sample(campos_buenos, qty_campos_a_utilizar)\n",
        "\n",
        "      # Paso de un vector a un string con los elementos separados por un signo de \"+\"\n",
        "      campos_random <- paste(campos_random, collapse= \" + \")\n",
        "\n",
        "      # Armo la formula para rpart\n",
        "      formulita <- paste0(\"clase_ternaria ~ \", campos_random)\n",
        "\n",
        "      # Genero el arbol de decision\n",
        "      modelo <- rpart(formulita,\n",
        "        data= dtrain,\n",
        "        xval= 0,\n",
        "        control= PARAM$rpart_current\n",
        "      )\n",
        "\n",
        "      # Aplico el modelo a los datos que no tienen clase\n",
        "      prediccion <- predict(modelo, dfuture, type= \"prob\")\n",
        "\n",
        "      # Acumulo la probabilidad\n",
        "      tb_prediccion[, prob_acumulada := prob_acumulada + prediccion[, \"BAJA+2\"]]\n",
        "\n",
        "      message(arbolito, \" \")\n",
        "    }\n",
        "\n",
        "    # 2. Generar el archivo final con el ensemble de 32 árboles\n",
        "\n",
        "    # El umbral de corte se calcula para un ensemble de N=32 arboles\n",
        "    # En el original es (1 / 40) * arbolito, para 32 arboles es (1/40) * 32 = 0.8\n",
        "    # Se utilizará el promedio de probabilidad, y el umbral de corte del archivo original\n",
        "    # (que es el corte de la probabilidad promedio para Ganancia, tipicamente 1/40 ~ 0.025)\n",
        "\n",
        "    # Se usará un umbral de corte simplificado (por ejemplo, 1/40) sobre la probabilidad promedio.\n",
        "    # El ensemble finaliza en el arbolito 32.\n",
        "    umbral_corte_promedio <- (1 / 40)\n",
        "\n",
        "    # Se calcula la probabilidad promedio\n",
        "    tb_prediccion[, prob_promedio := prob_acumulada / PARAM$num_trees_optimo]\n",
        "\n",
        "    # Clasificación final\n",
        "    tb_prediccion[, Predicted := as.numeric(prob_promedio > umbral_corte_promedio)]\n",
        "\n",
        "    archivo_kaggle <- paste0(\n",
        "      \"KA420_Ensemble32_m\", minsplit_actual, \"_d\", maxdepth_actual, \".csv\"\n",
        "    )\n",
        "\n",
        "    # Grabo el archivo\n",
        "    fwrite( tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "      file= archivo_kaggle,\n",
        "      sep= \",\"\n",
        "    )\n",
        "\n",
        "    # 3. Subida a Kaggle para evaluación de la Ganancia\n",
        "    comando <- \"kaggle competitions submit\"\n",
        "    competencia <- \"-c labo-i-2025-ba-analista-sr\"\n",
        "    arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "    mensaje <- paste0(\"-m 'minsplit=\", minsplit_actual,\n",
        "                      \" minbucket=\", PARAM$rpart_current$minbucket,\n",
        "                      \" maxdepth=\", maxdepth_actual,\n",
        "                      \" Ensemble de \", PARAM$num_trees_optimo, \" Arboles Azarosos'\")\n",
        "\n",
        "    linea <- paste( comando, competencia, arch, mensaje)\n",
        "    # salida <- system(linea, intern=TRUE) # Descomentar para la ejecución real\n",
        "    # cat(salida)\n",
        "    cat(\"Comando Kaggle (simulado):\", linea, \"\\n\")\n",
        "\n",
        "    # Volver al directorio base\n",
        "    setwd(paste0(\"/content/buckets/b1/exp/\", experimento_base))\n",
        "  }\n",
        "}\n",
        "\n",
        "# --- Comparación y Conclusiones (Manual) ---\n",
        "cat(\"\\n--- Tarea de Comparación ---\\n\")\n",
        "cat(\"Se han generado las predicciones para diferentes combinaciones de hiperparámetros de un ensemble de 32 Arboles Azarosos.\\n\")\n",
        "cat(\"Los archivos .csv han sido (simuladamente) subidos a Kaggle para medir la Ganancia.\\n\")\n",
        "cat(\"\\n**Pasos para la Validación Final:**\\n\")\n",
        "cat(\"1. Ejecutar este código para que los comandos 'kaggle competitions submit' se ejecuten (es necesario tener el entorno de Python/Kaggle configurado).\\n\")\n",
        "cat(\"2. **Analizar los resultados en el leaderboard de Kaggle** para encontrar la combinación (minsplit, maxdepth) que maximiza la Ganancia.\\n\")\n",
        "cat(\"3. **Comparar los hiperparámetros óptimos del ensemble de 32 (los que dan la mayor Ganancia en Kaggle) con los hiperparámetros óptimos de un árbol único** (que típicamente son más 'podados', con mayor minsplit y menor maxdepth).\\n\")\n",
        "cat(\"Se espera que los arbolitos del ensemble óptimo sean más overfitteros (ej., menor minsplit como 20, y mayor maxdepth como 10) que los de un árbol individual.\\n\")\n",
        "\n",
        "format(Sys.time(), \"%a %b %d %X %Y\")\n",
        "\n",
        "# --- Fin del Código R ---"
      ],
      "metadata": {
        "id": "o4UM4Rdl4D-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMr6Z1enOyd3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}